{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI for Biotechnology\n",
    "<span style=\"color:#AAA;font-size:14px;\" >Prof. Dr. Dominik Grimm</span>  \n",
    "<span style=\"color:#AAA;font-size:14px;\">Bioinformatics Research Lab</span>  \n",
    "<span style=\"color:#AAA;font-size:14px;\">TUM Campus Straubing for Biotechnology and Sustainability</span>  \n",
    "\n",
    "## Logistic Regression Exercise #5\n",
    "In this exercise we would like to compare the performance of different logistic regression models with different regualrization techniques. For this purpose, we first load the data from the hands-on tutorial, where we tried to predict if a certain plant flowers early or late using its genetics differences as features. We then remove 20% of the dataset into a seperate testing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Load plant genotype and phenotype\n",
    "X = np.loadtxt(\"plant_genotype.csv\", delimiter=\",\")\n",
    "y = np.loadtxt(\"plant_flowering_time_binary.csv\")\n",
    "\n",
    "#create train-test split, the test data will only be used for final evaluation\n",
    "#Please note that we replace the old X and y with the \"training\" split\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size = 0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing data will remain untouch in the model selection phase and will only be used in the end, after we have selected the best performing model to test its generalization abilities.  \n",
    "\n",
    "Such that we can compare the performance of different models we will split the remaining data into a training- and validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into validation and training\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple logistic regression model without regularization serves as baseline comparison partner. We estimate coefficients of the logistic regression model on the training data and evaluate the performance on the left out validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "#Train Simple Linear regression without regularization\n",
    "model = LogisticRegression(penalty=\"none\",solver=\"lbfgs\")\n",
    "\n",
    "#train logistic regression\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#test logistic regression on validation data\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "#compute metrics\n",
    "acc = metrics.accuracy_score(y_val, y_pred)\n",
    "auc = metrics.roc_auc_score(y_val,y_pred)\n",
    "precision = metrics.precision_score(y_val,y_pred)\n",
    "recall = metrics.recall_score(y_val,y_pred)\n",
    "mcc = metrics.matthews_corrcoef(y_val,y_pred)\n",
    "\n",
    "print(\"Accuracy (Val):\\t\\t%.2f\" % acc)\n",
    "print(\"ROC-AUC (Val):\\t\\t%.2f\" % auc)\n",
    "print(\"Precision (Val):\\t%.2f\" % precision)\n",
    "print(\"Recall (Val):\\t\\t%.2f\" % recall)\n",
    "print(\"MCC (Val):\\t\\t%.2f\" % mcc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot the estimated coefficients of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot beta estimates\n",
    "pl.scatter(np.arange(X.shape[1]),model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we train the logistic regression model using a l2-penalty with an internal cross-validation to find the optimal hyperparameter $C$. Again we plot the estiamted coefficients of the l2-lr model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "#Train Simple Linear regression without regularization\n",
    "model2 = LogisticRegressionCV(Cs=10, penalty=\"l2\",solver=\"lbfgs\",cv=5,max_iter=2000)\n",
    "\n",
    "#train logistic regression\n",
    "model2.fit(X_train,y_train)\n",
    "\n",
    "#test logistic regression on validation data\n",
    "y_pred = model2.predict(X_val)\n",
    "\n",
    "acc2 = metrics.accuracy_score(y_val, y_pred)\n",
    "auc2 = metrics.roc_auc_score(y_val,y_pred)\n",
    "precision2 = metrics.precision_score(y_val,y_pred)\n",
    "recall2 = metrics.recall_score(y_val,y_pred)\n",
    "mcc2 = metrics.matthews_corrcoef(y_val,y_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy (Val):\\t\\t%.2f\" % acc2)\n",
    "print(\"ROC-AUC (Val):\\t\\t%.2f\" % auc2)\n",
    "print(\"Precision (Val):\\t%.2f\" % precision2)\n",
    "print(\"Recall (Val):\\t\\t%.2f\" % recall2)\n",
    "print(\"MCC (Val):\\t\\t%.2f\" % mcc2)\n",
    "print(\"Best C:\\t\\t\\t%f\" %model2.C_)\n",
    "\n",
    "#Plot beta estimates\n",
    "pl.scatter(np.arange(X.shape[1]),model2.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.1\n",
    "Train a logistic regression model with a $l1$-penalty on the training data. Use cross-validation to find the optimal hyperparameter $C$ and evaluate the performance of your model on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Code comes here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the estimated coefficients of the $l1$-regularized logistic regression model and interprete the plot. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code comes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.2\n",
    "Train a logistic regression model with both, a $l1$- and a $l2$-penalty on the training data. Use a 5-fold cross-validation to find the optimal hyperparameter $C$ and $l1$ ratio and evaluate the performance of your model on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Range of hyperparameters\n",
    "Cs = 5 #use 5 C values between \n",
    "l1_ratios=[0,0.25,0.5,0.75,1.0] #tradeoff between l1 and l2 penalty\n",
    "\n",
    "#Your code comes here to train a logistic regression model with l1- and l2-penalty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.3\n",
    "Summerize the results of all 4 models in one ROC plot. Add labels and legends to the plot such that you can compare the different models. Which model performs best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate roc plot\n",
    "fig = pl.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "#Your code comes here\n",
    "\n",
    "ax.plot([0,1], [0,1], color=\"grey\",label=\"Random Classifier\",linestyle=\"--\")\n",
    "#Set axis labels\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "#Set axis limits\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xlim(0,1)\n",
    "#show grid in grey and set top and right axis to invisible\n",
    "ax.grid(color=\"#CCCCCC\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "pl.legend()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.4\n",
    "Select the best performing model from above and retrain it on the full training data with the optimal hyperparemters form the best model. Use then the untouched test data to evaluate the performance of the best model on unknown data. Does your model generalize? Is it good in predicting if a plant is early or late flowering? Visualize your results for the validation data and the testing data in a single roc plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain model on full training data\n",
    "best_C = model4.C_[0]\n",
    "best_l1_ratio = model4.l1_ratio_[0]\n",
    "\n",
    "#your code comes here:\n",
    "\n",
    "\n",
    "\n",
    "#Performance Metrics on Test set\n",
    "acc5 = metrics.accuracy_score(y_test, y_pred)\n",
    "auc5 = metrics.roc_auc_score(y_test,y_pred)\n",
    "precision5 = metrics.precision_score(y_test,y_pred)\n",
    "recall5 = metrics.recall_score(y_test,y_pred)\n",
    "mcc5 = metrics.matthews_corrcoef(y_test,y_pred)\n",
    "\n",
    "print(\"Accuracy (Val):\\t\\t%.2f\" % acc4)\n",
    "print(\"Accuracy (Test):\\t%.2f\" % acc5)\n",
    "print()\n",
    "print(\"ROC-AUC (Val):\\t\\t%.2f\" % auc4)\n",
    "print(\"ROC-AUC (Test):\\t\\t%.2f\" % auc5)\n",
    "print()\n",
    "print(\"Precision (Val):\\t%.2f\" % precision4)\n",
    "print(\"Precision (Test):\\t%.2f\" % precision5)\n",
    "print()\n",
    "print(\"Recall (Val):\\t\\t%.2f\" % recall4)\n",
    "print(\"Recall (Test):\\t\\t%.2f\" % recall5)\n",
    "print()\n",
    "print(\"MCC (Val):\\t\\t%.2f\" % mcc4)\n",
    "print(\"MCC (Test):\\t\\t%.2f\" % mcc5)\n",
    "\n",
    "#generate roc plot\n",
    "#your code comes here\n",
    "\n",
    "\n",
    "ax.plot([0,1], [0,1], color=\"grey\",label=\"Random Classifier\",linestyle=\"--\")\n",
    "#Set axis labels\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "#Set axis limits\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xlim(0,1)\n",
    "#show grid in grey and set top and right axis to invisible\n",
    "ax.grid(color=\"#CCCCCC\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "pl.legend()\n",
    "pl.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
